"""
ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•GraphSAGEæµ‹è¯•è„šæœ¬çš„æ‰€æœ‰å‡½æ•°
"""
import os
import torch
import pandas as pd
import numpy as np
import random
from datetime import datetime
import tempfile
import shutil

def create_mock_data():
    """åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•"""
    print("ğŸ”§ åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®...")
    
    # è®¾ç½®éšæœºç§å­
    np.random.seed(42)
    torch.manual_seed(42)
    random.seed(42)
    
    # æ¨¡æ‹Ÿå‚æ•°
    num_models = 10  # ç®€åŒ–ä¸º10ä¸ªæ¨¡å‹
    num_prompts = 50  # 50ä¸ªé—®é¢˜
    num_train_samples = 300  # è®­ç»ƒæ ·æœ¬æ•°
    num_test_samples = 100   # æµ‹è¯•æ ·æœ¬æ•°
    
    # åˆ›å»ºä¸´æ—¶æ•°æ®ç›®å½•
    temp_data_dir = "temp_test_data"
    os.makedirs(temp_data_dir, exist_ok=True)
    
    # 1. åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
    print("   - åˆ›å»ºæ¨¡æ‹Ÿè®­ç»ƒæ•°æ®...")
    train_data = []
    for i in range(num_train_samples):
        model_id = np.random.randint(0, num_models)
        prompt_id = np.random.randint(0, num_prompts)
        label = np.random.randint(0, 2)  # 0æˆ–1
        category_id = np.random.randint(0, 5)
        
        train_data.append({
            'prompt_id': prompt_id,
            'model_id': model_id,
            'category_id': category_id,
            'label': label,
            'prompt': f'This is test prompt {prompt_id}',
            'model_name': f'model_{model_id}',
            'category': f'category_{category_id}'
        })
    
    train_df = pd.DataFrame(train_data)
    train_df.to_csv(f"{temp_data_dir}/train.csv", index=False)
    print(f"      è®­ç»ƒæ•°æ®å½¢çŠ¶: {train_df.shape}")
    
    # 2. åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®
    print("   - åˆ›å»ºæ¨¡æ‹Ÿæµ‹è¯•æ•°æ®...")
    test_data = []
    for i in range(num_test_samples):
        model_id = np.random.randint(0, num_models)
        prompt_id = np.random.randint(0, num_prompts)
        label = np.random.randint(0, 2)
        category_id = np.random.randint(0, 5)
        
        test_data.append({
            'prompt_id': prompt_id,
            'model_id': model_id,
            'category_id': category_id,
            'label': label,
            'prompt': f'This is test prompt {prompt_id}',
            'model_name': f'model_{model_id}',
            'category': f'category_{category_id}'
        })
    
    test_df = pd.DataFrame(test_data)
    test_df.to_csv(f"{temp_data_dir}/test.csv", index=False)
    print(f"      æµ‹è¯•æ•°æ®å½¢çŠ¶: {test_df.shape}")
    
    # 3. åˆ›å»ºæ¨¡æ‹Ÿé—®é¢˜åµŒå…¥
    print("   - åˆ›å»ºæ¨¡æ‹Ÿé—®é¢˜åµŒå…¥...")
    question_embeddings = torch.randn(num_prompts, 768)  # 768ç»´åµŒå…¥
    torch.save(question_embeddings, f"{temp_data_dir}/question_embeddings.pth")
    print(f"      é—®é¢˜åµŒå…¥å½¢çŠ¶: {question_embeddings.shape}")
    
    # 4. åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹åµŒå…¥
    print("   - åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å‹åµŒå…¥...")
    model_embeddings = torch.randn(num_models, 1024)  # 1024ç»´åµŒå…¥
    torch.save(model_embeddings, f"{temp_data_dir}/model_embeddings_static.pth")
    print(f"      æ¨¡å‹åµŒå…¥å½¢çŠ¶: {model_embeddings.shape}")
    
    print(f"âœ… æ¨¡æ‹Ÿæ•°æ®åˆ›å»ºå®Œæˆï¼Œä¿å­˜åœ¨: {temp_data_dir}/")
    return temp_data_dir

def test_functions_with_mock_data(data_dir):
    """ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•æ‰€æœ‰å‡½æ•°"""
    print("\nğŸ§ª æµ‹è¯•GraphSAGEå‡½æ•°...")
    
    try:
        # å¯¼å…¥æµ‹è¯•è„šæœ¬ä¸­çš„å‡½æ•°
        import sys
        sys.path.append('.')
        
        from test_graphsage_random import (
            build_train_response_matrix_with_progress,
            build_test_response_matrix_with_progress,
            create_random_data_loaders,
            set_random_seed
        )
        from models.Embedllm_GraphSAGE import GraphSAGE_TextMF_dyn, build_model_graph
        
        # è®¾ç½®éšæœºç§å­
        set_random_seed(42)
        
        # 1. æµ‹è¯•æ•°æ®åŠ è½½
        print("\n1ï¸âƒ£ æµ‹è¯•æ•°æ®åŠ è½½...")
        train_data = pd.read_csv(f"{data_dir}/train.csv")
        test_data = pd.read_csv(f"{data_dir}/test.csv")
        question_embeddings = torch.load(f"{data_dir}/question_embeddings.pth", weights_only=True)
        model_embeddings = torch.load(f"{data_dir}/model_embeddings_static.pth", weights_only=True)
        
        print(f"   âœ… è®­ç»ƒæ•°æ®: {train_data.shape}")
        print(f"   âœ… æµ‹è¯•æ•°æ®: {test_data.shape}")
        print(f"   âœ… é—®é¢˜åµŒå…¥: {question_embeddings.shape}")
        print(f"   âœ… æ¨¡å‹åµŒå…¥: {model_embeddings.shape}")
        
        # 2. æµ‹è¯•éšæœºæ•°æ®åŠ è½½å™¨
        print("\n2ï¸âƒ£ æµ‹è¯•éšæœºæ•°æ®åŠ è½½å™¨...")
        train_loader, test_loader, shuffled_model_ids, id_mapping = create_random_data_loaders(
            train_data, test_data, batch_size=16, random_seed=42
        )
        
        print(f"   âœ… è®­ç»ƒåŠ è½½å™¨æ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"   âœ… æµ‹è¯•åŠ è½½å™¨æ‰¹æ¬¡æ•°: {len(test_loader)}")
        print(f"   âœ… æ‰“ä¹±åçš„æ¨¡å‹ID: {shuffled_model_ids}")
        
        # 3. æµ‹è¯•å“åº”çŸ©é˜µæ„å»º
        print("\n3ï¸âƒ£ æµ‹è¯•å“åº”çŸ©é˜µæ„å»º...")
        response_matrix_path = f"{data_dir}/test_response_matrix.pth"
        
        train_response_matrix, all_prompt_ids = build_train_response_matrix_with_progress(
            train_data, shuffled_model_ids, save_path=response_matrix_path
        )
        
        print(f"   âœ… è®­ç»ƒå“åº”çŸ©é˜µ: {train_response_matrix.shape}")
        print(f"   âœ… é—®é¢˜IDæ•°é‡: {len(all_prompt_ids)}")
        
        # æµ‹è¯•ä¿å­˜å’ŒåŠ è½½
        print("   - æµ‹è¯•å“åº”çŸ©é˜µä¿å­˜å’ŒåŠ è½½...")
        train_response_matrix_2, all_prompt_ids_2 = build_train_response_matrix_with_progress(
            train_data, shuffled_model_ids, save_path=response_matrix_path
        )
        
        if torch.equal(train_response_matrix, train_response_matrix_2):
            print("   âœ… å“åº”çŸ©é˜µä¿å­˜/åŠ è½½åŠŸèƒ½æ­£å¸¸")
        else:
            print("   âŒ å“åº”çŸ©é˜µä¿å­˜/åŠ è½½åŠŸèƒ½å¼‚å¸¸")
        
        # 4. æµ‹è¯•æµ‹è¯•å“åº”çŸ©é˜µæ„å»º
        print("\n4ï¸âƒ£ æµ‹è¯•æµ‹è¯•å“åº”çŸ©é˜µæ„å»º...")
        test_response_matrix = build_test_response_matrix_with_progress(
            test_data, shuffled_model_ids, all_prompt_ids
        )
        
        print(f"   âœ… æµ‹è¯•å“åº”çŸ©é˜µ: {test_response_matrix.shape}")
        
        # 5. æµ‹è¯•å›¾æ„å»º
        print("\n5ï¸âƒ£ æµ‹è¯•æ¨¡å‹å›¾æ„å»º...")
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        # ä½¿ç”¨å‰7ä¸ªæ¨¡å‹ä½œä¸ºè®­ç»ƒæ¨¡å‹ï¼ˆæ¨¡æ‹Ÿ90ä¸ªä¸­çš„å‰7ä¸ªï¼‰
        train_response_matrix_7 = train_response_matrix[:7]
        train_model_embeddings = model_embeddings[shuffled_model_ids[:7]]
        
        graph_data = build_model_graph(
            train_response_matrix_7,
            train_model_embeddings,
            k_neighbors=3,  # å‡å°‘é‚»å±…æ•°
            device=device
        )
        
        print(f"   âœ… å›¾èŠ‚ç‚¹æ•°: {graph_data.x.shape[0]}")
        print(f"   âœ… å›¾è¾¹æ•°: {graph_data.edge_index.shape[1]}")
        
        # 6. æµ‹è¯•æ¨¡å‹åˆå§‹åŒ–
        print("\n6ï¸âƒ£ æµ‹è¯•GraphSAGEæ¨¡å‹åˆå§‹åŒ–...")
        num_models = len(shuffled_model_ids)
        num_prompts = question_embeddings.shape[0]
        
        reordered_embeddings = model_embeddings[shuffled_model_ids]
        
        model = GraphSAGE_TextMF_dyn(
            question_embeddings=question_embeddings,
            model_embedding_dim=1024,
            alpha=0.1,
            num_models=num_models,
            num_prompts=num_prompts,
            model_embeddings=reordered_embeddings,
            is_dyn=True,
            frozen=False,
            hidden_dim=128,  # å‡å°‘éšè—å±‚ç»´åº¦
            num_layers=2,
            num_train_models=7  # å‰7ä¸ªä½œä¸ºè®­ç»ƒæ¨¡å‹
        )
        model.to(device)
        model.set_train_responses(train_response_matrix_7)
        
        print(f"   âœ… æ¨¡å‹å‚æ•°æ€»æ•°: {sum(p.numel() for p in model.parameters()):,}")
        print(f"   âœ… å¯è®­ç»ƒå‚æ•°: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}")
        
        # 7. æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­
        print("\n7ï¸âƒ£ æµ‹è¯•æ¨¡å‹å‰å‘ä¼ æ’­...")
        
        # å‡†å¤‡æœªè§æ¨¡å‹å“åº”ï¼ˆå3ä¸ªæ¨¡å‹ï¼Œå³æ¨¡å‹7,8,9ï¼‰
        unseen_model_ids = shuffled_model_ids[7:10]  # å3ä¸ªæ¨¡å‹
        
        # é‡æ–°æ„å»ºæ­£ç¡®çš„æµ‹è¯•å“åº”çŸ©é˜µ
        test_data_for_unseen = test_data[test_data["model_id"].isin(unseen_model_ids)]
        unseen_responses = torch.zeros(3, len(all_prompt_ids), dtype=torch.float32)
        
        prompt_id_to_idx = {prompt_id: idx for idx, prompt_id in enumerate(all_prompt_ids)}
        
        for _, row in test_data_for_unseen.iterrows():
            model_id = row["model_id"]
            prompt_id = row["prompt_id"]
            label = row["label"]
            
            if model_id in unseen_model_ids and prompt_id in prompt_id_to_idx:
                unseen_model_idx = list(unseen_model_ids).index(model_id)
                prompt_idx = prompt_id_to_idx[prompt_id]
                unseen_responses[unseen_model_idx, prompt_idx] = label
        
        print(f"   - æœªè§æ¨¡å‹å“åº”çŸ©é˜µå½¢çŠ¶: {unseen_responses.shape}")
        
        # æµ‹è¯•1: åªæœ‰è®­ç»ƒæ¨¡å‹çš„æ‰¹æ¬¡
        print("   - æµ‹è¯•è®­ç»ƒæ¨¡å‹å‰å‘ä¼ æ’­...")
        batch_size = 4
        train_model_ids = torch.randint(0, 7, (batch_size,)).to(device)  # åªé€‰æ‹©å‰7ä¸ªè®­ç»ƒæ¨¡å‹
        test_prompt_ids = torch.randint(0, num_prompts, (batch_size,)).to(device)
        
        model.eval()
        with torch.no_grad():
            logits = model(graph_data, train_model_ids, test_prompt_ids, 
                          unseen_responses.to(device), test_mode=True)
            predictions = model.predict(graph_data, train_model_ids, test_prompt_ids, 
                                      unseen_responses.to(device))
        
        print(f"      âœ… è®­ç»ƒæ¨¡å‹logitså½¢çŠ¶: {logits.shape}")
        print(f"      âœ… è®­ç»ƒæ¨¡å‹é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
        
        # æµ‹è¯•2: åªæœ‰æœªè§æ¨¡å‹çš„æ‰¹æ¬¡
        print("   - æµ‹è¯•æœªè§æ¨¡å‹å‰å‘ä¼ æ’­...")
        unseen_model_ids_batch = torch.tensor([7, 8, 9], dtype=torch.long).to(device)  # å3ä¸ªæ¨¡å‹
        unseen_prompt_ids = torch.randint(0, num_prompts, (3,)).to(device)
        
        with torch.no_grad():
            logits = model(graph_data, unseen_model_ids_batch, unseen_prompt_ids, 
                          unseen_responses.to(device), test_mode=True)
            predictions = model.predict(graph_data, unseen_model_ids_batch, unseen_prompt_ids, 
                                      unseen_responses.to(device))
        
        print(f"      âœ… æœªè§æ¨¡å‹logitså½¢çŠ¶: {logits.shape}")
        print(f"      âœ… æœªè§æ¨¡å‹é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
        print(f"      âœ… æœªè§æ¨¡å‹é¢„æµ‹å€¼: {predictions.cpu().numpy()}")
        
        # æµ‹è¯•3: æ··åˆæ‰¹æ¬¡ï¼ˆè®­ç»ƒæ¨¡å‹+æœªè§æ¨¡å‹ï¼‰
        print("   - æµ‹è¯•æ··åˆæ¨¡å‹å‰å‘ä¼ æ’­...")
        mixed_model_ids = torch.tensor([0, 1, 7, 8], dtype=torch.long).to(device)  # 2ä¸ªè®­ç»ƒ+2ä¸ªæœªè§
        mixed_prompt_ids = torch.randint(0, num_prompts, (4,)).to(device)
        
        with torch.no_grad():
            logits = model(graph_data, mixed_model_ids, mixed_prompt_ids, 
                          unseen_responses.to(device), test_mode=True)
            predictions = model.predict(graph_data, mixed_model_ids, mixed_prompt_ids, 
                                      unseen_responses.to(device))
        
        print(f"      âœ… æ··åˆæ¨¡å‹logitså½¢çŠ¶: {logits.shape}")
        print(f"      âœ… æ··åˆæ¨¡å‹é¢„æµ‹å½¢çŠ¶: {predictions.shape}")
        print(f"      âœ… æ··åˆæ¨¡å‹é¢„æµ‹å€¼: {predictions.cpu().numpy()}")
        
        # 8. æµ‹è¯•æ•°æ®åŠ è½½å™¨è¿­ä»£
        print("\n8ï¸âƒ£ æµ‹è¯•æ•°æ®åŠ è½½å™¨è¿­ä»£...")
        train_batch_count = 0
        test_batch_count = 0
        
        for models, prompts, labels in train_loader:
            train_batch_count += 1
            if train_batch_count == 1:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
                print(f"   âœ… è®­ç»ƒæ‰¹æ¬¡å½¢çŠ¶ - æ¨¡å‹: {models.shape}, é—®é¢˜: {prompts.shape}, æ ‡ç­¾: {labels.shape}")
                break
        
        for models, prompts, labels in test_loader:
            test_batch_count += 1
            if test_batch_count == 1:  # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ‰¹æ¬¡
                print(f"   âœ… æµ‹è¯•æ‰¹æ¬¡å½¢çŠ¶ - æ¨¡å‹: {models.shape}, é—®é¢˜: {prompts.shape}, æ ‡ç­¾: {labels.shape}")
                break
        
        print(f"   âœ… è®­ç»ƒåŠ è½½å™¨æ€»æ‰¹æ¬¡æ•°: {len(train_loader)}")
        print(f"   âœ… æµ‹è¯•åŠ è½½å™¨æ€»æ‰¹æ¬¡æ•°: {len(test_loader)}")
        
        print("\nğŸ‰ æ‰€æœ‰å‡½æ•°æµ‹è¯•é€šè¿‡ï¼")
        return True
        
    except Exception as e:
        print(f"\nâŒ å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def cleanup_temp_data(data_dir):
    """æ¸…ç†ä¸´æ—¶æ•°æ®"""
    if os.path.exists(data_dir):
        shutil.rmtree(data_dir)
        print(f"ğŸ§¹ æ¸…ç†ä¸´æ—¶æ•°æ®: {data_dir}")

def check_real_data_files():
    """æ£€æŸ¥çœŸå®æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ” æ£€æŸ¥çœŸå®æ•°æ®æ–‡ä»¶...")
    print("=" * 60)
    
    required_files = [
        "data/train.csv",
        "data/test.csv", 
        "data/question_embeddings.pth",
        "data/model_embeddings_static.pth"
    ]
    
    all_exist = True
    
    for file_path in required_files:
        if os.path.exists(file_path):
            print(f"âœ… {file_path} - å­˜åœ¨")
            
            # å°è¯•åŠ è½½æ–‡ä»¶ä»¥æ£€æŸ¥æ ¼å¼
            try:
                if file_path.endswith('.csv'):
                    data = pd.read_csv(file_path)
                    print(f"   ğŸ“Š æ•°æ®å½¢çŠ¶: {data.shape}")
                    print(f"   ğŸ“‹ åˆ—å: {list(data.columns)}")
                    if 'model_id' in data.columns:
                        unique_models = data['model_id'].nunique()
                        print(f"   ğŸ¤– å”¯ä¸€æ¨¡å‹æ•°: {unique_models}")
                    if 'prompt_id' in data.columns:
                        unique_prompts = data['prompt_id'].nunique()
                        print(f"   â“ å”¯ä¸€é—®é¢˜æ•°: {unique_prompts}")
                        
                elif file_path.endswith('.pth'):
                    tensor = torch.load(file_path, map_location='cpu', weights_only=True)
                    print(f"   ğŸ“ å¼ é‡å½¢çŠ¶: {tensor.shape}")
                    print(f"   ğŸ”¢ æ•°æ®ç±»å‹: {tensor.dtype}")
                    
            except Exception as e:
                print(f"   âš ï¸ åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
                
        else:
            print(f"âŒ {file_path} - ä¸å­˜åœ¨")
            all_exist = False
        
        print()
    
    return all_exist

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ GraphSAGEæµ‹è¯•è„šæœ¬åŠŸèƒ½éªŒè¯")
    print("=" * 80)
    
    # 1. ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•æ‰€æœ‰å‡½æ•°
    temp_data_dir = create_mock_data()
    
    try:
        success = test_functions_with_mock_data(temp_data_dir)
        
        if success:
            print("\nâœ… æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•é€šè¿‡ï¼æ‰€æœ‰å‡½æ•°å·¥ä½œæ­£å¸¸ã€‚")
        else:
            print("\nâŒ æ¨¡æ‹Ÿæ•°æ®æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥ä»£ç ã€‚")
            return False
            
    finally:
        cleanup_temp_data(temp_data_dir)
    
    # 2. æ£€æŸ¥çœŸå®æ•°æ®æ–‡ä»¶
    real_data_exists = check_real_data_files()
    
    print("=" * 80)
    if success and real_data_exists:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¯ä»¥è¿è¡Œå®Œæ•´çš„æµ‹è¯•è„šæœ¬ï¼š")
        print("   python test_graphsage_random.py")
    elif success:
        print("âœ… å‡½æ•°æµ‹è¯•é€šè¿‡ï¼Œä½†ç¼ºå°‘çœŸå®æ•°æ®æ–‡ä»¶")
        print("   è¯·ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨åè¿è¡Œ: python test_graphsage_random.py")
    else:
        print("âŒ å‡½æ•°æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç åé‡è¯•")
    
    return success and real_data_exists

if __name__ == "__main__":
    main()
